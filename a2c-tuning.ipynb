{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy, MlpLnLstmPolicy, CnnPolicy, CnnLstmPolicy, CnnLnLstmPolicy\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines import A2C\n",
    "\n",
    "from gym.utils import seeding\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "import numpy as np\n",
    "\n",
    "from ads_utils import load_data, plot, Environment\n",
    "from tqdm import tqdm\n",
    "\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"name\": \"a2c sweep\",\n",
    "  \"method\": \"grid\",\n",
    "  \"parameters\": {\n",
    "      \"learning_rate\": {\n",
    "            \"values\": [0.001, 0.0001, 0.00001]\n",
    "        },\n",
    "      \"n_steps\": {\n",
    "          \"values\": [10, 50, 70, 100]  \n",
    "        },\n",
    "      \"n_ticks\": {\n",
    "          \"values\": [5, 20, 50, 100]\n",
    "      },\n",
    "      \"momentum\": {\n",
    "        \"values\": [0, 0.1, 0.5, 0.9]  \n",
    "      }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: cmh1del2\n",
      "Sweep URL: https://wandb.ai/ads/a2c-sweep-all-params-val-data2/sweeps/cmh1del2\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity=\"ads\", project=\"a2c-sweep-all-params-val-data2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = load_data([i for i in range(1, 12 + 1)])['close'].to_list()\n",
    "val_data = load_data([i for i in range(13, 18 + 1)])['close'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_env(ticks):\n",
    "    INITIAL_BALANCE = 10_000\n",
    "    # sample training data\n",
    "#     start = randint(0, len(training_data) - 10000 - 1) \n",
    "#     sample = training_data[start: start + 10000]\n",
    "    return Environment(training_data, balance=INITIAL_BALANCE, past_ticks=ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_env(ticks):\n",
    "    INITIAL_BALANCE = 10_000\n",
    "    return Environment(val_data, balance=INITIAL_BALANCE, past_ticks=ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    run = wandb.init()\n",
    "    print(\"config:\", dict(run.config))\n",
    "    \n",
    "    N_EPOCH = 50\n",
    "    env = create_training_env(run.config.n_ticks)\n",
    "    env.reset()\n",
    "    model = A2C('MlpPolicy', env, verbose=0, \n",
    "                learning_rate=run.config.learning_rate, \n",
    "                n_steps=run.config.n_steps,\n",
    "                momentum=run.config.momentum)\n",
    "    \n",
    "    for i in range(N_EPOCH):\n",
    "        print(f'Epoch {i}')\n",
    "        model.learn(total_timesteps=10000)\n",
    "\n",
    "    val_env = create_validation_env(run.config.n_ticks)\n",
    "    state = val_env.reset(rand_start=False)\n",
    "    \n",
    "    for i in range(len(val_data)):\n",
    "        action, _ = model.predict(state)\n",
    "\n",
    "        price, portfolio_value = val_env.get_data()\n",
    "\n",
    "        state, reward, done, _ = val_env.step(action)\n",
    "        wandb.log({'portfolio_value': portfolio_value, 'reward': reward})\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zzyhc0cf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_steps: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_ticks: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mads\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads3.6",
   "language": "python",
   "name": "ads3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
